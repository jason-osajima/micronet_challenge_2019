{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate nasnet\n",
    "Evaluate nasnet using micronet challenge [scoring guidelines](https://micronet-challenge.github.io/scoring_and_submission.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/workspace/micronet_challenge_2019/'\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "os.chdir(PATH)\n",
    "from conf import settings\n",
    "from utils.model_utils import get_network\n",
    "from utils.model_counting import count_Conv2d, count_NormalCell, count_ReductionCell\n",
    "from utils.model_counting import countReLU, count_AdaptiveAvgPool2d, count_FullyConnected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args):\n",
    "    \"\"\"\n",
    "    Takes as input a string of args\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-net', type=str, required=True, help='net type')\n",
    "    parser.add_argument('-gpu', type=bool, default=True, help='use gpu or not')\n",
    "    parser.add_argument('-w', type=int, default=2, help='number of workers for dataloader')\n",
    "    parser.add_argument('-b', type=int, default=32, help='batch size for dataloader')\n",
    "    parser.add_argument('-s', type=bool, default=True, help='whether shuffle the dataset')\n",
    "    parser.add_argument('-warm', type=int, default=1, help='warm up training phase')\n",
    "    parser.add_argument('-lr', type=float, default=0.1, help='initial learning rate')\n",
    "    return parser.parse_args(args.split())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = '-net nasnet -b 32 -lr 0.025'\n",
    "args = parse_args(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = get_network(args, use_gpu=args.gpu)\n",
    "\n",
    "# load model from checkpoint\n",
    "CHECKPOINT_PATH = PATH + 'checkpoint/nasnet-595-best.pth'\n",
    "net.load_state_dict(torch.load(CHECKPOINT_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def get_transform_test():\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(settings.CIFAR100_TRAIN_MEAN, settings.CIFAR100_TRAIN_STD),\n",
    "    ])\n",
    "    return transform_test\n",
    "\n",
    "def get_test_dataloader(mean, std, batch_size=16, num_workers=2, shuffle=True):\n",
    "    \"\"\" return training dataloader\n",
    "    Args:\n",
    "        mean: mean of cifar100 test dataset\n",
    "        std: std of cifar100 test dataset\n",
    "        path: path to cifar100 test python dataset\n",
    "        batch_size: dataloader batchsize\n",
    "        num_workers: dataloader num_works\n",
    "        shuffle: whether to shuffle \n",
    "    Returns: cifar100_test_loader:torch dataloader object\n",
    "    \"\"\"\n",
    "\n",
    "    transform_test = get_transform_test()\n",
    "    cifar100_test = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
    "    cifar100_test_loader = DataLoader(\n",
    "        cifar100_test, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n",
    "\n",
    "    return cifar100_test_loader\n",
    "\n",
    "\n",
    "# get the cifar100 test dataset\n",
    "cifar100_test_loader = get_test_dataloader(\n",
    "    settings.CIFAR100_TRAIN_MEAN,\n",
    "    settings.CIFAR100_TRAIN_STD,\n",
    "    num_workers=args.w,\n",
    "    batch_size=args.b,\n",
    "    shuffle=args.s\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy\n",
    "Accuracy should be above 80 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "correct = 0.0\n",
    "\n",
    "for (images, labels) in cifar100_test_loader:\n",
    "    images = Variable(images)\n",
    "    labels = Variable(labels)\n",
    "\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "\n",
    "    outputs = net(images)\n",
    "    _, preds = outputs.max(1)\n",
    "    correct += preds.eq(labels).sum()\n",
    "\n",
    "acc = correct.float() / len(cifar100_test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for nasnet: 81.2800%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy for ' + args.net + ': ' + '{0:.4%}'.format(acc.item()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Storage\n",
    "The model performs no quantization, so we use freebie quantization and divide the total number of parameters by 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nasnet has 5221624 total parameters.\n",
      "nasnet achieves a parameter score of 0.07153\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "print(args.net +  ' has ' + '{0}'.format(total_params) + ' total parameters.')\n",
    "\n",
    "total_params_freebie = total_params / 2\n",
    "benchmark_params = 36.5e6\n",
    "parameter_score = total_params_freebie / benchmark_params\n",
    "print(args.net + ' achieves a parameter score of ' + '{0:.4}'.format(parameter_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math Operations\n",
    "The model performs no quantization, so we use freebie quantization and divide the total number of multiplies by 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stem\n",
    "The stem for nasnet consists of one Conv2d followed by BachNorm2d Operation. We assume a [fused](https://tehnokv.com/posts/fusing-batchnorm-and-conv) conv + batchnorm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mults: 1216512 and adds: 1171456 for stem layer.\n"
     ]
    }
   ],
   "source": [
    "total_mults = total_adds = 0\n",
    "x = torch.Tensor(1, 3, 32, 32).cuda()\n",
    "conv_layer = net.stem[0]\n",
    "\n",
    "# (1) Conv2D and (3) BatchNorm2d\n",
    "flop_mults, flop_adds = count_Conv2d(conv_layer, x)\n",
    "total_mults += flop_mults; total_adds += flop_adds\n",
    "x = net.stem[0](x)\n",
    "# assume fused conv layer at batch norm at inference\n",
    "x = net.stem[1](x)\n",
    "print('Total mults: ' + '{0}'.format(total_mults) + ' and adds: ' + '{0}'.format(total_adds) + ' for stem layer.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell Layers\n",
    "Nasnet has several sequential and reduction layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Cell (Layers 0 - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = None\n",
    "\n",
    "for i in range(4):\n",
    "    normalcell = net.cell_layers[i]\n",
    "    flop_mults, flop_adds = count_NormalCell(normalcell, x, prev)\n",
    "    total_mults += flop_mults; total_adds += flop_adds\n",
    "    x, prev = normalcell((x, prev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction Cell (Layer 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reductioncell = net.cell_layers[4]\n",
    "flop_mults, flop_adds = count_ReductionCell(reductioncell, x, prev)\n",
    "total_mults += flop_mults; total_adds += flop_adds\n",
    "x, prev = reductioncell((x, prev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Cell (Layers 5 - 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5, 9):\n",
    "    normalcell = net.cell_layers[i]\n",
    "    flop_mults, flop_adds = count_NormalCell(normalcell, x, prev)\n",
    "    total_mults += flop_mults; total_adds += flop_adds\n",
    "    x, prev = normalcell((x, prev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction Cell (Layer 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reductioncell = net.cell_layers[9]\n",
    "flop_mults, flop_adds = count_ReductionCell(reductioncell, x, prev)\n",
    "total_mults += flop_mults; total_adds += flop_adds\n",
    "x, prev = reductioncell((x, prev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Cell (Layers 10 - 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10, 14):\n",
    "    normalcell = net.cell_layers[i]\n",
    "    flop_mults, flop_adds = count_NormalCell(normalcell, x, prev)\n",
    "    total_mults += flop_mults; total_adds += flop_adds\n",
    "    x, prev = normalcell((x, prev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relu\n",
    "flop_mults, flop_adds = countReLU(x)\n",
    "total_mults += flop_mults; total_adds += flop_adds\n",
    "x = net.relu(x)\n",
    "\n",
    "# Adaptive Average Pooling 2D\n",
    "pool_layer = net.avg\n",
    "flop_mults, flop_adds = count_AdaptiveAvgPool2d(pool_layer, x)\n",
    "total_mults += flop_mults; total_adds += flop_adds\n",
    "x = pool_layer(x)\n",
    "\n",
    "# changing the view\n",
    "x = x.view(x.size(0), -1)\n",
    "\n",
    "# Fully connected layer\n",
    "fc_layer = net.fc\n",
    "flop_mults, flop_adds = count_FullyConnected(fc_layer, x)\n",
    "total_mults += flop_mults; total_adds += flop_adds\n",
    "x = fc_layer(x)\n",
    "\n",
    "n_classes = 100\n",
    "assert x.shape[1] == n_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mults: 662173600 and adds: 659313248 for nasnet.\n",
      "nasnet achieves an ops score of 0.09441\n"
     ]
    }
   ],
   "source": [
    "total_mults_freebie = total_mults / 2\n",
    "benchmark_ops = 10.49e9\n",
    "ops_score = (total_mults_freebie + total_adds) / benchmark_ops\n",
    "print('Total mults: ' + '{0}'.format(total_mults) + ' and adds: ' + '{0}'.format(total_adds) + ' for nasnet.')\n",
    "print(args.net + ' achieves an ops score of ' + '{0:.4}'.format(ops_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Score: 0.16594283\n"
     ]
    }
   ],
   "source": [
    "print('Final Score: ' + '{0:.8}'.format(ops_score + parameter_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
